Kubernetes was developed by google, it manages containers

Open source container orchastration tool 
Helps you manage them in different environments -> like physical machiners, cloud machines or vms

 Managing thousands of containers spread through different environments throgh scripts can be tedious

also the trend from monolith to microservices resulted into the use of thousands of containers

Hence the increased demand for the proper way of managing those hundreds of containers

Tools like kunernetrs guarantee the folloeing:
=> High availability no downtime
 -> scalability and high performance
=> disaster recovery || back up and restore

K8 components explained:
Node => Is a simple server or a virtial machine

Pod => is a smallest unit of k8s
	it is an abstracion of a container, what pod does is create these running environents or a layer o	on top of a container, and the reason is kubernetes wants to abstract away the container runtime and 	container technologies so that you can replace them if you want to and because you dont want to work d	directly with docker or container technology you use in kubernetes so that you only interact with kubernetes layer
	 Pod us meant to run 1 container inside it 

'
Kunernetes offers a virtual netwoek out of the box which which means each pod gets its own ip adress
the pod gets its own ip adress not the container and each pod can communicate with each other using and jip adress which is an internal ip adress and not a public one, so ,my container can communicate with the database using an ip adress 

Note: Pods in kubernetes are ephemeral meaning they can die very easly

and in case of anything going wrong the pod will die and the new one will be creates and a new adress will be created and assigned a new ip adress, This makes it inconvinient as if comminication was through ip asress if the pod dies then the one cretes will lose communication with the newly created pos as they have different ip adress

due to that another component of kubernetes called service is used


SERVICE and INGRESS:
Service is a permanent ip adress that can be attached to each pod so my-app will have its own service and pod will have its own service, the lifecycle of a pod and a service are not connected so even if the pod dies the ip adress will stay 

External service is a service that opens the services to the external sources

Insteas of the esternal request going directly to the intenal services they will fitstly go to ingress then the fowarded to the internal services

CONFIGMAP and SECRETS:
configmap is an external configuration to your application eg urls of the databases etc, also you can put the database username and passwords but this would be insecure

secrets: its just like config map but used to secure secret data
They are not stored in plain text but in base 64 encoded format

The built in security mechanisms are not enabled ny default

You can use this as an environmenal variable or a proprty value


VOLUNES:
Data stprage and storage:
How it accomplishes this is by attaching the actual phydical drive to your pod which means it can be on the same local machine which means the same pod is running ot it could be a remote storage outside of a kubernetes cluster, it could be cloud storage or on premise storage which is not a part of kubernetes structure	you just have a reference to it

 KUbernetes doesnt hanhle data persistence so you hace to handle it yourself 


DEPLOYMENT and STATEFUL SETS:
IF my pod dies then i will have downtime which is a bad thig as my site wont be accesible

A service has two functionalities:
=> provides permanent ip adress
=> is a load balancer -> will catch a request and foward it to the the service which is least busy

To create a new pod you woulnt create another pod but define a blueprint and specify the number of pods you want to run. That blueprint is called deployment.

And you wont be working with pods you will be working with deployments because there you can specify the number if pods you want ans you can scale up or down number of replica of pods you need.

Note: Pod is layer of abstraction on top of containers and deployments are a layer of abstraction on top of pods

Now if one replicas of your application dies the service will foward the request to another one so that the application will be accesible to the user 

You cant replicate database using deployments, reason being database has state meaning its data this means if we have the replicas of database they will have to access the same storage and you will need some mechanisms to know which services are writing to that storage and which are reading from what storage in order to avoid data inconsistencies

deployments are for stateless apps
statefulSet for stateful apps or databases => the reads and writes for the databases ara synchronized

Deploying stateful sets can be tedious and thats why its common to host the stateful applications outside the container ans the stateless ones inside as they easly scale withought having to worry about data losses

SUMMARY OF KUBERNETES COMPONENTS:
=> Pod - abstraction of containers
=> Service - communication between pods
=> Ingress - used to route traffic into the cluster
=> External configuration usind Configmaps and Secrets
=> Volumes - handles data persistence
=> Blueprints using deployments and statefulSets

These are te core or the basic concepts, just using these you can build pretty powerful kubernetes cludters

K8 architecture explained:
Master processes
Each container will have multiple pods running in them 
-> three processes must be installed on every node

Worker nodes are the nodes that actually do the work, hence the name

The first proccess that need to run on every node is a container runtime
the processes that schedules the pods and the containers underneath is KUBELET
which is process of kubernetes itself unlike container runtime
Kubeletes interacts with both the node and the container 

Kubeletes starts the pod with the container inside and assigning resources to the container like cou ram and storage resoutces 
Usually kubernetes cluster is made up of multiple nodes which must have container services and kuberkets installed 

The third service that is respnsible for fowarding requests from services to pods is kube proxy that must be installed on every node and kubeproxy have an intelligent fowarding inside that make sure the indoemation works in the perfotmant way with low overhead For example if my-app is make request to database the request is not fowaeded to a random database but the satabase pod inside the same pod and hence avoiding the netwoek overhead of sending the request to the other machine

SUMMARY: 3Processes
=>Kubelet
=>Kube proxy  -these two must be installed on every node
=> container runtime


INTERRACTION WITH THE CLUSTER:

How to schedule a pod?
monitor?
reschedule or restart a pod?
join a ner node?

All these processes are done by master nodes: 4 of these process are:


=> Api server -> is like a cluster gateway its a way you can interact with the woeker nodes using kubernetes dashboard or kubelet cli
it acts as a gate keeper  for authentication to make sure only the authenticated users gets to the cluster

if you have a request => API server => Validates request => other processes => pod 
and if you eant to query the cluster health or the status of your deployment you make the request throgh the API server and it gives you the response 

2ndly: Scheduler
Schedile a new pod: API server -> scheduler => pod(the secheduler is intelligent to decide on which node pod will be scheduled or bext component will be scheduled)

Firstly it will look at your request and see how muvh of the resources you need and its gonna go through the woeker nodes and see the availavle resources in each and one of them, on the least busy is when the pod will be scheduled

TIP: Scheduler decides on which node the new pod will be scheduled, the process that actually start that container is a cubelet 


#rprocess: Controller manager
It detects state changes like crashes, and tries to recover the cluster state as soon as possible 

so contoller manager=> scheduler => Kubelet


4thrly etcd
This is like a cluster brain 
Cluster changes are stored in the key value store, and the reason its a cluster brain is because all these mechanisms with controller etc woek works because of the etcd data
For example how does resources available on each worker node, did the cluster state change? is the cluster healthy? all these are answered by having the info from etcd cluster

what is not stored:
The actual application data
etcd just storest the cluster information used for master processes to communicate with the work processes and vice versa

These master processes are crucial and each master node runs its master processes where the API server is load balanced and etcd stores distributed storage across all the master nodes

The actual hardware of master and worker resources differ, master nodes are importance but the have less load od work so they need less resources where the worker nodes do the actual work to  run those containers and therefore they need more resources and as the application scales you can add more nodes to meet the required application resources, so if you need the extra master nodes you get the bare metal server install the master processes and add it to kubernetes cluster
 and the same applies if you need two woeker nodes you get two bare metal servers install the woeker node processes and all it to kubernetes cluster and this way you can infinitely increase the power of kubernetes cluster as it replication level and resource demand increases


MINIKUBE and KUBRCTL:
Production cluster setup
-> it will have multiple masters atleast two in production setup 
-> and multiple worker nodes

minikube is this one test/local cluster setup where it is a one node cluster  when master and worker processes both run on the same machine and this will have docker runtime pre-insalled

so this minikube will create a virtual box on your laptop
=> node runs in that virtual box 
=> 1 k8s cluster

which can be used for testing purposes 
now you have a cluster you need a way to interact with your cluster and thats where this comes in:

KUBECTL:
kubectl is a commandline tool for k8 structure

Note: Minicube runs both master and worker processes

You first have to interact with the api server to do any kubernetes work
 so to interact with Api server can be through api, ui or cli of which all of these are all clients

and kubectl is the most poweful of all the clients


IMPORTANT: kubectl isnt just for minikube clustet 	if yoou have a cloud cluster or hybrid cluster minikubectl is the one to interact with the setup

!!!!Since minikube uses virtualization hence virtualization has to be enabled in your machine
 and you need to install some tyoe jof some hypervisor 

COMMANDS:
Minikube start => Creates and start the cluster
 options --vm-driver=hyperkit

kubectl get nodes => gets status of nodes

minikube status => also gets you the status of the running kubes

kubectl version => gives the version of installed kubernetes -> this will show you the client and the server version of this 


IMPORTANT:
Minikube CLI is for starting or deleting the cluster

Kubectl CLU is for configuring the minikube cluster

BASIC KUBECTLCOMMANDS:
Prequesities:
Have minicube cli and kubectl installed in your system 

You are going to be using kubectl for the control of anything

commands: 
kubectl get nodes
kubectl get pods
kubectl get services

to create anything kubectl create -h will give you the man pages for creating

In creating there is no pod option, there is an abstraction and that is deployment and that will create pods underneath

to create the creation is made from image and this is the command:
kubectl create deployment nginx-depl image=nginx

-> this will download the latest image of nginx from docker Hub

To see the seployments you can do : kubectl get deployment and if you want to get the pod: kubectl get pod

when i create the deployment it is the blueprint for creating the pods and the most basic configuration is providing the name and the image 


Between deployment and a pod there is another another abstraction layer called replicaset which is autimatically managed by kuberneter deployments 

command to get the replicaser: kubectl get replicaset

the podname has the prefix of deployment and replicaset is and its own id

the replocaset is basically managing the replicas of a pod, You wont be manually required to create or delete a replicaset file but you gonna be working with deployments directly  to create multiple replicas you can provide te options to do that 


check this out:
a deployment manages a:
replicaset manages a:
a pod is an abstraction of 
a container 

 thats the hierrachy and everything below the deployment should be managed by kubernetes

to edit:
kubectl edit deployment [name] => this will give you the auto generated configuration file with default values because at the command if you gave name and an image everything else is auto generated

and if you edit it will open the text editor and yoou can change some configurations and after saving the info the old pod eg. if you changed the image version will be terminated and the new one will be start running 

51:37
